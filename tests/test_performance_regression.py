#!/usr/bin/env python3
"""
æ€§èƒ½å›æ­¸æ¸¬è©¦ - ç¢ºä¿é‡æ§‹éç¨‹ä¸­æ€§èƒ½ä¸æœƒé¡¯è‘—æƒ¡åŒ–

é€™å€‹æ¸¬è©¦æ¨¡çµ„å°ˆé–€æ¸¬é‡å’Œæ¯”è¼ƒï¼š
1. æ¨¡çµ„å°å…¥æ™‚é–“
2. é¡åˆå§‹åŒ–æ€§èƒ½
3. é—œéµæ–¹æ³•åŸ·è¡Œæ™‚é–“
4. å…§å­˜ä½¿ç”¨æƒ…æ³
5. ä»£ç¢¼è¤‡é›œåº¦æŒ‡æ¨™
"""

import sys
import os
import time
import unittest
import importlib
import psutil
import gc
from typing import Dict, List, Any, Callable
import json
from functools import wraps

# Add project root to path
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

try:
    import lazy_blacktea_pyqt
except ImportError as e:
    print(f"âŒ ç„¡æ³•å°å…¥ä¸»æ¨¡çµ„: {e}")
    sys.exit(1)


def measure_time(func: Callable) -> Callable:
    """æ™‚é–“æ¸¬é‡è£é£¾å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        start_time = time.perf_counter()
        result = func(*args, **kwargs)
        end_time = time.perf_counter()
        execution_time = end_time - start_time
        return result, execution_time
    return wrapper


def measure_memory(func: Callable) -> Callable:
    """å…§å­˜æ¸¬é‡è£é£¾å™¨"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        gc.collect()  # å¼·åˆ¶åƒåœ¾å›æ”¶
        process = psutil.Process()
        memory_before = process.memory_info().rss / 1024 / 1024  # MB

        result = func(*args, **kwargs)

        gc.collect()  # å†æ¬¡å¼·åˆ¶åƒåœ¾å›æ”¶
        memory_after = process.memory_info().rss / 1024 / 1024  # MB
        memory_diff = memory_after - memory_before

        return result, memory_diff
    return wrapper


class PerformanceRegressionTest(unittest.TestCase):
    """æ€§èƒ½å›æ­¸æ¸¬è©¦é¡"""

    @classmethod
    def setUpClass(cls):
        """è¨­ç½®æ¸¬è©¦ç’°å¢ƒ"""
        cls.module = lazy_blacktea_pyqt
        cls.baseline_file = "tests/refactoring_baseline.json"
        cls.performance_threshold = {
            'time_regression': 50.0,  # 50%çš„æ™‚é–“å›æ­¸ç®—åš´é‡
            'memory_regression': 100.0,  # 100%çš„å…§å­˜å›æ­¸ç®—åš´é‡
        }

        # åŠ è¼‰åŸºç·šæ•¸æ“š
        try:
            with open(cls.baseline_file, 'r', encoding='utf-8') as f:
                cls.baseline_data = json.load(f)
            print("âœ… åŸºç·šæ•¸æ“šåŠ è¼‰æˆåŠŸ")
        except FileNotFoundError:
            print("âš ï¸  æœªæ‰¾åˆ°åŸºç·šæ•¸æ“šï¼Œå°‡å‰µå»ºæ–°çš„åŸºç·š")
            cls.baseline_data = {}
        except Exception as e:
            print(f"âŒ åŠ è¼‰åŸºç·šæ•¸æ“šå¤±æ•—: {e}")
            cls.baseline_data = {}

    def test_module_import_performance(self):
        """æ¸¬è©¦æ¨¡çµ„å°å…¥æ€§èƒ½"""
        print("\nâš¡ æ¸¬è©¦æ¨¡çµ„å°å…¥æ€§èƒ½...")

        @measure_time
        def import_module():
            return importlib.reload(lazy_blacktea_pyqt)

        # æ¸¬é‡å¤šæ¬¡å–å¹³å‡å€¼
        times = []
        for i in range(5):
            _, import_time = import_module()
            times.append(import_time)

        avg_import_time = sum(times) / len(times)
        print(f"  ğŸ“Š å¹³å‡å°å…¥æ™‚é–“: {avg_import_time:.4f}ç§’")

        # èˆ‡åŸºç·šæ¯”è¼ƒ
        baseline_import_time = self.baseline_data.get('performance_metrics', {}).get('import_time', 0)
        if baseline_import_time > 0:
            regression_percent = ((avg_import_time - baseline_import_time) / baseline_import_time) * 100
            print(f"  ğŸ“ˆ èˆ‡åŸºç·šæ¯”è¼ƒ: {regression_percent:+.1f}%")

            self.assertLess(
                regression_percent, self.performance_threshold['time_regression'],
                f"å°å…¥æ™‚é–“å›æ­¸éå¤§: {regression_percent:.1f}%"
            )
        else:
            print("  âš ï¸  ç„¡åŸºç·šæ•¸æ“šå¯æ¯”è¼ƒ")

    def test_class_analysis_performance(self):
        """æ¸¬è©¦é¡åˆ†ææ€§èƒ½"""
        print("\nâš¡ æ¸¬è©¦é¡åˆ†ææ€§èƒ½...")

        @measure_time
        def analyze_main_class():
            if hasattr(self.module, 'WindowMain'):
                WindowMain = getattr(self.module, 'WindowMain')
                # åˆ†æé¡çš„æ–¹æ³•å’Œå±¬æ€§
                methods = [m for m in dir(WindowMain) if callable(getattr(WindowMain, m)) and not m.startswith('_')]
                return len(methods)
            return 0

        _, analysis_time = analyze_main_class()
        print(f"  ğŸ“Š é¡åˆ†ææ™‚é–“: {analysis_time:.4f}ç§’")

        # èˆ‡åŸºç·šæ¯”è¼ƒ
        baseline_analysis_time = self.baseline_data.get('performance_metrics', {}).get('WindowMain_analysis_time', 0)
        if baseline_analysis_time > 0:
            regression_percent = ((analysis_time - baseline_analysis_time) / baseline_analysis_time) * 100
            print(f"  ğŸ“ˆ èˆ‡åŸºç·šæ¯”è¼ƒ: {regression_percent:+.1f}%")

            self.assertLess(
                regression_percent, self.performance_threshold['time_regression'],
                f"é¡åˆ†ææ™‚é–“å›æ­¸éå¤§: {regression_percent:.1f}%"
            )
        else:
            print("  âš ï¸  ç„¡åŸºç·šæ•¸æ“šå¯æ¯”è¼ƒ")

    def test_memory_usage_stability(self):
        """æ¸¬è©¦å…§å­˜ä½¿ç”¨ç©©å®šæ€§"""
        print("\nğŸ’¾ æ¸¬è©¦å…§å­˜ä½¿ç”¨ç©©å®šæ€§...")

        @measure_memory
        def load_and_analyze_module():
            # é‡æ–°è¼‰å…¥æ¨¡çµ„ä¸¦åˆ†æ
            module = importlib.reload(lazy_blacktea_pyqt)
            if hasattr(module, 'WindowMain'):
                WindowMain = getattr(module, 'WindowMain')
                # åŸ·è¡Œä¸€äº›åŸºæœ¬åˆ†æ
                methods = dir(WindowMain)
                return len(methods)
            return 0

        method_count, memory_diff = load_and_analyze_module()
        print(f"  ğŸ“Š å…§å­˜è®ŠåŒ–: {memory_diff:+.2f} MB")
        print(f"  ğŸ”¢ åˆ†ææ–¹æ³•æ•¸: {method_count}")

        # å…§å­˜ä½¿ç”¨ä¸æ‡‰è©²éåº¦å¢é•·
        self.assertLess(
            abs(memory_diff), 50.0,  # å…§å­˜è®ŠåŒ–ä¸æ‡‰è¶…é50MB
            f"å…§å­˜ä½¿ç”¨è®ŠåŒ–éå¤§: {memory_diff:+.2f} MB"
        )

    def test_code_complexity_metrics(self):
        """æ¸¬è©¦ä»£ç¢¼è¤‡é›œåº¦æŒ‡æ¨™"""
        print("\nğŸ“ æ¸¬è©¦ä»£ç¢¼è¤‡é›œåº¦æŒ‡æ¨™...")

        # è¨ˆç®—ç•¶å‰çš„ä»£ç¢¼æŒ‡æ¨™
        current_metrics = self._calculate_current_metrics()

        # èˆ‡åŸºç·šæ¯”è¼ƒ
        baseline_metrics = self.baseline_data.get('code_metrics', {})

        if baseline_metrics:
            print("  ğŸ“Š ä»£ç¢¼æŒ‡æ¨™æ¯”è¼ƒ:")

            metrics_to_check = ['total_lines', 'function_count', 'class_count']
            for metric in metrics_to_check:
                current_value = current_metrics.get(metric, 0)
                baseline_value = baseline_metrics.get(metric, 0)

                if baseline_value > 0:
                    change_percent = ((current_value - baseline_value) / baseline_value) * 100
                    status = "âœ…" if abs(change_percent) < 20 else "âš ï¸"
                    print(f"    {status} {metric}: {baseline_value} -> {current_value} ({change_percent:+.1f}%)")

                    # ä»£ç¢¼è¡Œæ•¸ä¸æ‡‰è©²åœ¨é‡æ§‹ä¸­é¡¯è‘—å¢åŠ 
                    if metric == 'total_lines':
                        self.assertLess(
                            change_percent, 20.0,
                            f"ä»£ç¢¼è¡Œæ•¸å¢é•·éå¤š: {change_percent:.1f}%"
                        )
        else:
            print("  âš ï¸  ç„¡åŸºç·šæŒ‡æ¨™å¯æ¯”è¼ƒ")

    def test_method_count_stability(self):
        """æ¸¬è©¦æ–¹æ³•æ•¸é‡ç©©å®šæ€§"""
        print("\nğŸ”¢ æ¸¬è©¦æ–¹æ³•æ•¸é‡ç©©å®šæ€§...")

        if hasattr(self.module, 'WindowMain'):
            WindowMain = getattr(self.module, 'WindowMain')
            current_method_count = len([m for m in dir(WindowMain)
                                      if callable(getattr(WindowMain, m))
                                      and not m.startswith('_')])

            print(f"  ğŸ“Š ç•¶å‰å…¬å…±æ–¹æ³•æ•¸: {current_method_count}")

            # èˆ‡åŸºç·šæ¯”è¼ƒ
            baseline_method_count = self.baseline_data.get('performance_metrics', {}).get('WindowMain_method_count', 0)
            if baseline_method_count > 0:
                change_percent = ((current_method_count - baseline_method_count) / baseline_method_count) * 100
                print(f"  ğŸ“ˆ èˆ‡åŸºç·šæ¯”è¼ƒ: {change_percent:+.1f}%")

                # åœ¨é‡æ§‹éç¨‹ä¸­ï¼Œæ–¹æ³•æ•¸é‡å¯èƒ½æœƒæœ‰æ‰€è®ŠåŒ–ï¼Œä½†ä¸æ‡‰è©²éåº¦å¢åŠ 
                self.assertLess(
                    change_percent, 50.0,
                    f"æ–¹æ³•æ•¸é‡å¢é•·éå¤šï¼Œå¯èƒ½è¡¨ç¤ºé‡æ§‹ä¸ç•¶: {change_percent:.1f}%"
                )

                # æ–¹æ³•æ•¸é‡ä¹Ÿä¸æ‡‰è©²å¤§å¹…æ¸›å°‘ï¼ˆé™¤éæ˜¯æœ‰æ„çš„é‡æ§‹ï¼‰
                self.assertGreater(
                    change_percent, -30.0,
                    f"æ–¹æ³•æ•¸é‡æ¸›å°‘éå¤šï¼Œå¯èƒ½ç ´å£äº†åŠŸèƒ½: {change_percent:.1f}%"
                )
            else:
                print("  âš ï¸  ç„¡åŸºç·šæ•¸æ“šå¯æ¯”è¼ƒ")

    def test_overall_performance_benchmark(self):
        """ç¶œåˆæ€§èƒ½åŸºæº–æ¸¬è©¦"""
        print("\nğŸ† ç¶œåˆæ€§èƒ½åŸºæº–æ¸¬è©¦...")

        benchmark_results = {}

        # æ¸¬è©¦1: æ¨¡çµ„é‡è¼‰æ€§èƒ½
        @measure_time
        def reload_module():
            return importlib.reload(lazy_blacktea_pyqt)

        _, reload_time = reload_module()
        benchmark_results['reload_time'] = reload_time

        # æ¸¬è©¦2: é¡æª¢æŸ¥æ€§èƒ½
        @measure_time
        def inspect_classes():
            classes = []
            for name in dir(self.module):
                obj = getattr(self.module, name)
                if hasattr(obj, '__module__') and obj.__module__ == self.module.__name__:
                    if hasattr(obj, '__dict__'):
                        classes.append(name)
            return len(classes)

        class_count, inspect_time = inspect_classes()
        benchmark_results['inspect_time'] = inspect_time
        benchmark_results['class_count'] = class_count

        print(f"  ğŸ“Š ç¶œåˆåŸºæº–çµæœ:")
        print(f"    ğŸ”„ é‡è¼‰æ™‚é–“: {reload_time:.4f}ç§’")
        print(f"    ğŸ” æª¢æŸ¥æ™‚é–“: {inspect_time:.4f}ç§’")
        print(f"    ğŸ“ é¡æ•¸é‡: {class_count}")

        # ç¸½é«”æ€§èƒ½ä¸æ‡‰è©²å¤ªå·®
        total_time = reload_time + inspect_time
        self.assertLess(total_time, 1.0, f"ç¸½é«”æ“ä½œæ™‚é–“éé•·: {total_time:.4f}ç§’")

    def _calculate_current_metrics(self) -> Dict[str, int]:
        """è¨ˆç®—ç•¶å‰çš„ä»£ç¢¼æŒ‡æ¨™"""
        metrics = {}

        try:
            file_path = "lazy_blacktea_pyqt.py"
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()

                metrics.update({
                    'total_lines': len(content.splitlines()),
                    'non_empty_lines': len([line for line in content.splitlines() if line.strip()]),
                    'comment_lines': len([line for line in content.splitlines() if line.strip().startswith('#')]),
                    'class_count': content.count('class '),
                    'function_count': content.count('def '),
                    'file_size': len(content)
                })
        except Exception as e:
            metrics['error'] = str(e)

        return metrics

    def test_no_major_memory_leaks(self):
        """æ¸¬è©¦æ²’æœ‰æ˜é¡¯çš„å…§å­˜æ´©æ¼"""
        print("\nğŸ” æ¸¬è©¦å…§å­˜æ´©æ¼...")

        initial_memory = psutil.Process().memory_info().rss / 1024 / 1024

        # åŸ·è¡Œå¤šæ¬¡æ“ä½œ
        for i in range(10):
            importlib.reload(lazy_blacktea_pyqt)
            if hasattr(lazy_blacktea_pyqt, 'WindowMain'):
                WindowMain = getattr(lazy_blacktea_pyqt, 'WindowMain')
                # åŸ·è¡Œä¸€äº›åŸºæœ¬æ“ä½œ
                methods = dir(WindowMain)
            gc.collect()

        final_memory = psutil.Process().memory_info().rss / 1024 / 1024
        memory_growth = final_memory - initial_memory

        print(f"  ğŸ“Š å…§å­˜å¢é•·: {memory_growth:+.2f} MB")

        # å…§å­˜å¢é•·ä¸æ‡‰è©²éå¤š
        self.assertLess(
            memory_growth, 20.0,
            f"å¯èƒ½å­˜åœ¨å…§å­˜æ´©æ¼: {memory_growth:+.2f} MB"
        )


def run_performance_tests():
    """é‹è¡Œæ€§èƒ½å›æ­¸æ¸¬è©¦çš„ä¾¿åˆ©å‡½æ•¸"""
    print("âš¡ é‹è¡Œæ€§èƒ½å›æ­¸æ¸¬è©¦...")

    # å‰µå»ºæ¸¬è©¦å¥—ä»¶
    loader = unittest.TestLoader()
    suite = unittest.TestSuite()

    # æ·»åŠ æ€§èƒ½æ¸¬è©¦
    suite.addTests(loader.loadTestsFromTestCase(PerformanceRegressionTest))

    # é‹è¡Œæ¸¬è©¦
    runner = unittest.TextTestRunner(verbosity=2)
    result = runner.run(suite)

    print("\n" + "="*60)
    print("ğŸ“Š æ€§èƒ½å›æ­¸æ¸¬è©¦å ±å‘Š")
    print("="*60)

    if result.wasSuccessful():
        print("âœ… æ‰€æœ‰æ€§èƒ½æ¸¬è©¦é€šéï¼")
        print("ğŸš€ æ€§èƒ½è¡¨ç¾è‰¯å¥½ï¼Œå¯ä»¥å®‰å…¨ç¹¼çºŒé‡æ§‹")
    else:
        print("âŒ ç™¼ç¾æ€§èƒ½å›æ­¸å•é¡Œï¼")
        print("âš ï¸  è«‹åœ¨ç¹¼çºŒé‡æ§‹å‰å„ªåŒ–æ€§èƒ½")

        if result.failures:
            print(f"\nå¤±æ•—çš„æ¸¬è©¦ ({len(result.failures)}):")
            for test, traceback in result.failures:
                print(f"  - {test}")

        if result.errors:
            print(f"\néŒ¯èª¤çš„æ¸¬è©¦ ({len(result.errors)}):")
            for test, traceback in result.errors:
                print(f"  - {test}")

    return result.wasSuccessful()


if __name__ == '__main__':
    success = run_performance_tests()
    sys.exit(0 if success else 1)